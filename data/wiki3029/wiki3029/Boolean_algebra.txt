It is weaker in the sense that it does not of itself imply representability.
While we have not shown the Venn diagrams for the constants 0 and 1, they are trivial, being respectively a white box and a dark box, neither one containing a circle.
''But not'' is synonymous with ''and not''.
There is no self-dual binary operation that depends on both its arguments.
When used to combine situational assertions such as "the block is on the table" and "cats drink milk," which naively are either true or false, the meanings of these logical connectives often have the meaning of their logical counterparts.
All concrete Boolean algebras satisfy the laws (by proof rather than fiat), whence every concrete Boolean algebra is a Boolean algebra according to our definitions.
The empty set and ''X''.
For so-called "active-high" logic, 0 is represented by a voltage close to zero or "ground", while 1 is represented by a voltage close to the supply voltage; active-low reverses this.
A consequence of the first of these laws is 1∨1 = 1, which is false in ordinary algebra, where 1+1 = 2.
Because each output can have two possible values, there are a total of 24 = 16 possible binary Boolean operations.
Today, all modern general purpose computers perform their functions using two-value Boolean logic; that is, their electrical circuits are a physical manifestation of two-value Boolean logic.
:A '''Boolean algebra''' is a complemented distributive lattice.
makes more sense than the reverse order.
These four functions form a group under function composition, isomorphic to the Klein four-group, acting on the set of Boolean polynomials.
Shannon already had at his disposal the abstract mathematical apparatus, thus he cast his switching algebra as the two-element Boolean algebra.
In fact, M. H. Stone proved in 1936 that every Boolean algebra is isomorphic to a field of sets.
They achieve this in various ways: as voltages on wires in high-speed circuits and capacitive storage devices, as orientations of a magnetic domain in ferromagnetic storage devices, as holes in punched cards or paper tape, and so on.
In this translation between Boolean algebra and propositional logic, Boolean variables ''x,y''… become '''propositional variables''' (or '''atoms''') ''P,Q'',…, Boolean terms such as ''x''∨''y'' become propositional formulas ''P''∨''Q'', 0 becomes ''false'' or '''⊥''', and 1 becomes ''true'' or '''T'''.
A ''proof'' in an axiom system ''A'' is a finite nonempty sequence of propositions each of which is either an instance of an axiom of ''A'' or follows by some rule of ''A'' from propositions appearing earlier in the proof (thereby disallowing circular reasoning).
The laws ''Complementation'' 1 and 2, together with the monotone laws, suffice for this purpose and can therefore be taken as one possible ''complete'' set of laws or axiomatization of Boolean algebra.
Boolean operations are used in digital logic to combine the bits carried on individual wires, thereby interpreting them over {0,1}.
When values and operations can be paired up in a way that leaves everything important unchanged when all pairs are switched simultaneously, we call the members of each pair '''dual''' to each other.
Again we have finitely many subsets of an infinite set forming a concrete Boolean algebra, with Example 2 arising as the case ''n'' = 0 of no curves.
A '''law''' of Boolean algebra is an identity such as ''x''∨(''y''∨''z'') = (''x''∨''y'')∨''z'' between two Boolean terms, where a '''Boolean term''' is defined as an expression built up from variables and the constants 0 and 1 using the operations ∧, ∨, and ¬.
* Doublequotes are used to combine whitespace-separated words into a single search term.
The value of the input is represented by a voltage on the lead.
01101000110101100101010101001011.
"Search term 1" OR "Search term 2"
Boolean algebra was introduced by George Boole in his first book ''The Mathematical Analysis of Logic'' (1847), and set forth more fully in his ''An Investigation of the Laws of Thought'' (1854).
However it would not be identical to our original Boolean algebra because now we find ∨ behaving the way ∧ used to do and vice versa.
In 1933 Edward Huntington showed that if the basic operations are taken to be ''x''∨''y'' and ¬''x'', with ''x''∧''y'' considered a derived operation (e.g.
A more complicated example of a self-dual operation is (''x''∧''y'') ∨ (''y''∧''z'') ∨ (''z''∧''x'').
Instead of showing that the Boolean laws are satisfied, we can instead postulate a set ''X'', two binary operations on ''X'', and one unary operation, and ''require'' that those operations satisfy the laws of Boolean algebra.
The result of instantiating ''P'' in an abstract proposition is called an '''instance''' of the proposition.
The Duality Principle, or De Morgan's laws, can be understood as asserting that complementing all three ports of an AND gate converts it to an OR gate and vice versa, as shown in Figure 4 below.
Each gate implements a Boolean operation, and is depicted schematically by a shape indicating the operation.
Instead of elementary algebra where the values of the variables are numbers, and the main operations are addition and multiplication, the main operations of Boolean algebra are the conjunction ''and'' denoted as ∧, the disjunction ''or'' denoted as ∨, and the negation ''not'' denoted as ¬.
:Every Boolean algebra is representable.
A '''tautology''' is a propositional formula that is assigned truth value ''1'' by every truth assignment of its propositional variables to an arbitrary Boolean algebra (or, equivalently, every truth assignment to the two element Boolean algebra).
The result is the same as if we shaded that region which is both outside the ''x'' circle ''and'' outside the ''y'' circle, i.e.
The remaining four laws can be falsified in ordinary algebra by taking all variables to be 1, for example in Absorption Law 1 the left hand side is 1(1+1) = 2 while the right hand side is 1, and so on.
It excludes the possibility of both ''x'' and ''y''.
Given any complete axiomatization of Boolean algebra, such as the axioms for a complemented distributive lattice, a sufficient condition for an algebraic structure of this kind to satisfy all the Boolean laws is that it satisfy just those axioms.
The candidates for membership in a set work just like the wires in a digital computer: each candidate is either a member or a nonmember, just as each wire is either high or low.
It is convenient when referring to generic propositions to use Greek letters Φ, Ψ,… as metavariables (variables outside the language of propositional calculus, used when talking ''about'' propositional calculus) to denote propositions.
The commutativity laws for ∧ and ∨ can be seen from the symmetry of the diagrams: a binary operation that was not commutative would not have a symmetric diagram because interchanging ''x'' and ''y'' would have the effect of reflecting the diagram horizontally and any failure of commutativity would then appear as a failure of symmetry.
This observation is easily proved as follows.
We say that complement is a '''self-dual''' operation.
It is also used in set theory and statistics.
There being sixteen binary Boolean operations, this must leave eight operations with an even number of 1's in their truth tables.
Boolean algebra is not sufficient to capture logic formulas using quantifiers, like those from first order logic.
:The laws satisfied by all Boolean algebras coincide with those satisfied by the prototypical Boolean algebra.
A simple-minded answer is "all Boolean laws," which can be defined as all equations that hold for the Boolean algebra of 0 and 1.
Whereas the foregoing has addressed the subject of Boolean algebra, this section deals with mathematical objects called Boolean algebras, defined in full generality as any model of the Boolean laws.
characteristic of modern or abstract algebra.
The most common computer architectures use ordered sequences of Boolean values, called bits, of 32 or 64 values, e.g.
The semantics of propositional logic rely on '''truth assignment'''s.
Bit vectors indexed by the set of natural numbers are infinite sequences of bits, while those indexed by the reals in the unit interval 0,1 are packed too densely to be able to write conventionally but nonetheless form well-defined indexed families (imagine coloring every point of the interval 0,1 either black or white independently; the black points then form an arbitrary subset of 0,1).
Two of these are the constants 0 and 1 (as binary operations that ignore both their inputs); four are the operations that depend nontrivially on exactly one of their two inputs, namely ''x'', ''y'', ¬''x'', and ¬''y''; and the remaining two are ''x''⊕''y'' (XOR) and its complement ''x''≡''y''.
So there are still some cosmetic differences to show that we've been fiddling with the notation, despite the fact that we're still using 0s and 1s.
The concept can be extended to terms involving other Boolean operations such as ⊕, →, and ≡, but such extensions are unnecessary for the purposes to which the laws are put.
But suppose we rename 0 and 1 to 1 and 0 respectively.
Venn diagrams are helpful in visualizing laws.
This strong relationship implies a weaker result strengthening the observation in the previous subsection to the following easy consequence of representability.
(The availability of instantiation as part of the machinery of propositional calculus avoids the need for metavariables within the language of propositional calculus, since ordinary propositional variables can be considered within the language to denote arbitrary propositions.
Operations with this property are said to be '''monotone'''.
The closely related model of computation known as a Boolean circuit relates time complexity (of an algorithm) to circuit complexity.
If ''x'' is true then the value of ''x''&nbsp;→&nbsp;''y'' is taken to be that of ''y''.
Since there are infinitely many such laws this is not a terribly satisfactory answer in practice, leading to the next question: does it suffice to require only finitely many laws to hold?
We say that Boolean algebra is '''finitely axiomatizable''' or '''finitely based.'''
From this bit vector viewpoint, a concrete Boolean algebra can be defined equivalently as a nonempty set of bit vectors all of the same length (more generally, indexed by the same set) and closed under the bit vector operations of bitwise ∧, ∨, and ¬, as in 1010∧0110 = 0010, 1010∨0110 = 1110, and ¬1010 = 0101, the bit vector realizations of intersection, union, and complement respectively.
The obvious next question is answered positively as follows.
There are eight such because the "odd-bit-out" can be either 0 or 1 and can go in any of four positions in the truth table.
In practice, the tight constraints of high speed, small size, and low power combine to make noise a major factor.
Questions can be similar: the order "Is the sky blue, and why is the sky blue?"
They do not behave like the integers 0 and 1, for which 1 + 1 = 2, but may be identified with the elements of the two-element field GF(2), that is, integer arithmetic modulo 2, for which 1 + 1 = 0.
Then the set of all 22''n'' possible unions of regions (including the empty set obtained as the union of the empty set of regions and ''X'' obtained as the union of all 2''n'' regions) is closed under union, intersection, and complement relative to ''X'' and therefore forms a concrete Boolean algebra.
The end product is completely indistinguishable from what we started with.
The customary metavariable denoting an antecedent or part thereof is Γ, and for a succedent Δ; thus Γ,''A''  Δ would denote a sequent whose succedent is a list Δ and whose antecedent is a list Γ with an additional proposition ''A'' appended after it.
For example, one might use respectively 0, 1, 2, and 3 volts to code a four-symbol alphabet on a wire, or holes of different sizes in a punched card.
This two-element algebra shows that a concrete Boolean algebra can be finite even when it consists of subsets of an infinite set.
Equivalence counterpart in arithmetic mod 2 is ''x'' + ''y'' + 1.
In this context, "numeric" means that the computer treats sequences of bits as binary numbers (base two numbers) and executes arithmetic operations like add, subtract, multiply, or divide.
Programmers therefore have the option of working in and applying the rules of either numeric algebra or Boolean algebra as needed.
With sets however an element is either in or out.
In classical semantics, only the two-element Boolean algebra is used, while in Boolean-valued semantics arbitrary Boolean algebras are considered.
Given two operands, each with two possible values, there are 22 = 4 possible combinations of inputs.
Conjunctive commands about behavior are like behavioral assertions, as in ''get dressed and go to school''.
Addition and multiplication then play the Boolean roles of XOR (exclusive-or) and AND (conjunction) respectively, with disjunction ''x''∨''y'' (inclusive-or) definable as ''x'' + ''y'' + ''xy''.
The last proposition is the '''theorem''' proved by the proof.
To begin with, some of the above laws are implied by some of the others.
Defined in terms of arithmetic it is addition mod&nbsp;2 where 1&nbsp;+&nbsp;1 =&nbsp;0.
Conversely every theorem Φ = Ψ of Boolean algebra corresponds to the tautologies (Φ∨¬Ψ) ∧ (¬Φ∨Ψ) and (Φ∧Ψ) ∨ (¬Φ∧¬Ψ).
Conversely any law that fails for some concrete Boolean algebra must have failed at a particular bit position, in which case that position by itself furnishes a one-bit counterexample to that law.
Every law of Boolean algebra follows logically from these axioms.
Of course, it is possible to code more than two symbols in any given medium.
The resulting sixteen possibilities give rise to only eight Boolean operations, namely those with an odd number of 1's in their truth table.
Every tautology Φ of propositional logic can be expressed as the Boolean equation Φ = 1, which will be a theorem of Boolean algebra.
At run time the video card interprets the byte as the raster operation indicated by the original expression in a uniform way that requires remarkably little hardware and which takes time completely independent of the complexity of the expression.
One change we did not need to make as part of this interchange was to complement.
Then it would still be Boolean algebra, and moreover operating on the same values.
The following examples use a syntax supported by Google.
The third diagram represents complement ¬''x'' by shading the region ''not'' inside the circle.
The problem of determining whether the variables of a given Boolean (propositional) formula can be assigned in such a way as to make the formula evaluate to true is called the Boolean satisfiability problem (SAT), and is of importance to theoretical computer science, being the first problem shown to be NP-complete.
The second operation, ''x''&nbsp;⊕&nbsp;''y'', or J''xy'', is called '''exclusive or''' (often abbreviated as XOR) to distinguish it from disjunction as the inclusive kind.
We shall however reach that goal via the surprisingly stronger observation that, up to isomorphism, all Boolean algebras are concrete.
It can be seen that every field of subsets of ''X'' must contain the empty set and ''X''.
The second diagram represents disjunction ''x''∨''y'' by shading those regions that lie inside either or both circles.
This quite nontrivial result depends on the Boolean prime ideal theorem, a choice principle slightly weaker than the axiom of choice, and is treated in more detail in the article Stone's representation theorem for Boolean algebras.
The identity or do-nothing operation ''x'' (copy the input to the output) is also self-dual.
Modern electronic design automation tools for VLSI circuits often rely on an efficient representation of Boolean functions known as (reduced ordered) binary decision diagrams (BDD) for logic synthesis and formal verification.
Algebraically, negation (NOT) is replaced with 1&nbsp;−&nbsp;''x'', conjunction (AND) is replaced with multiplication (), and disjunction (OR) is defined via De Morgan's law.
Algebra being a fundamental tool in any area amenable to mathematical treatment, these considerations combine to make the algebra of two values of fundamental importance to computer hardware, mathematical logic, and set theory.
:A Boolean algebra is called '''representable''' when it is isomorphic to a concrete Boolean algebra.
To clarify, writing down further laws of Boolean algebra cannot give rise to any new consequences of these axioms, nor can it rule out any model of them.
In more focused situations such as a court of law or theorem-based mathematics however it is deemed advantageous to frame questions so as to admit a simple yes-or-no answer—is the defendant guilty or not guilty, is the proposition true or false—and to disallow any other answer.
The second complement law, ''x''∨¬''x'' = 1, says that everything is either inside or outside the ''x'' circle.
Interpreting these values as logical truth values yields a multi-valued logic, which forms the basis for fuzzy logic and probabilistic logic.
Can this list be made shorter yet?
One obvious use is in building a complex shape from simple shapes simply as the union of the latter.
In everyday relaxed conversation, nuanced or complex answers such as "maybe" or "only on the weekend" are acceptable.
However much of a straitjacket this might prove in practice for the respondent, the principle of the simple yes-no question has become a central feature of both judicial and mathematical logic, making two-valued logic deserving of organization and study in its own right.
Taking ''x'' = 2 in the second law shows that it is not an ordinary algebra law either, since 2×2 = 4.
Nondegeneracy ensures the existence of at least one bit position because there is only one empty bit vector.
These values are represented with the bits (or binary digits), namely 0 and 1.
Modern video cards offer all 223&nbsp;=&nbsp;256 ternary operations for this purpose, with the choice of operation being a one-byte (8-bit) parameter.
One motivating application of propositional calculus is the analysis of propositions and deductive arguments in natural language.
As far as their outputs are concerned, constants and constant functions are indistinguishable; the difference is that a constant takes no arguments, called a ''zeroary'' or ''nullary'' operation, while a constant function takes one argument, which it ignores, and is a ''unary'' operation.
These semantics permit a translation between  tautologies of propositional logic and equational theorems of Boolean algebra.
Propositional calculus restricts attention to abstract propositions, those built up from propositional variables using Boolean operations.
The set of finite and cofinite sets of integers, where a cofinite set is one omitting only finitely many integers.
In contrast, in a list of some but not all of the same laws, there could have been Boolean laws that did not follow from those on the list, and moreover there would have been models of the listed laws that were not Boolean algebras.
"Search term 1" −"Search term 2"
According to Huntington, the term "Boolean algebra" was first suggested by Sheffer in 1913.
To see the first absorption law, ''x''∧(''x''∨''y'') = ''x'', start with the diagram in the middle for ''x''∨''y'' and note that the portion of the shaded area in common with the ''x'' circle is the whole of the ''x'' circle.
It is thus a formalism for describing logical relations in the same way that ordinary algebra describes numeric relations.
* The OR keyword is used for logical OR:
Let ''n'' be a square-free positive integer, one not divisible by the square of an integer, for example 30 but not 12.
All of the laws treated so far have been for conjunction and disjunction.
The lines on the left of each gate represent input wires or ''ports''.
However this exclusion conflicts with the preferred purely equational definition of "Boolean algebra," there being no way to rule out the one-element algebra using only equations—&nbsp;0&nbsp;≠&nbsp;1 does not count, being a negated equation.
In the 1930s, while studying switching circuits, Claude Shannon observed that one could also apply the rules of Boole's algebra in this setting, and he introduced '''switching algebra''' as a way to analyze and design circuits by algebraic means in terms of logic gates.
Another form is sequent calculus, which has two sorts, propositions as in ordinary propositional calculus, and pairs of lists of propositions called sequents, such as ''A''∨''B'', ''A''∧''C'',…  ''A'', ''B''→''C'',….
In circuit engineering settings today, there is little need to consider other Boolean algebras, thus "switching algebra" and "Boolean algebra" are often used interchangeably.
The three Venn diagrams in the figure below represent respectively conjunction ''x''∧''y'', disjunction ''x''∨''y'', and complement ¬''x''.
(As an aside, historically ''X'' itself was required to be nonempty as well to exclude the degenerate or one-element Boolean algebra, which is the one exception to the rule that all Boolean algebras satisfy the same equations since the degenerate algebra satisfies every equation.
We begin with a special case of the notion definable without reference to the laws, namely concrete Boolean algebras, and then give the formal definition of the general notion.
The convention of putting such a circle on any port means that the signal passing through this port is complemented on the way through, whether it is an input or output port.
This axiomatization is by no means the only one, or even necessarily the most natural given that we did not pay attention to whether some of the axioms followed from others but simply chose to stop when we noticed we had enough laws, treated further in the section on axiomatizations.
In the case of Boolean algebras the answer is yes.
Nonmonotonicity enters via complement ¬ as follows.
Hence those divisors form a Boolean algebra.
When the only basic operation is the binary NAND operation ¬(''x''∧''y''), Stephen Wolfram has proposed in his book ''A New Kind of Science'' the single axiom (((''xy'')''z'')(''x''((''xz'')''x''))) = ''z'' as a one-equation axiomatization of Boolean algebra, where for convenience here ''xy'' denotes the NAND rather than the AND of ''x'' and ''y''.
This makes it hard to distinguish between symbols when there are several possible symbols that could occur at a single site.
Two-valued logic can be extended to multi-valued logic, notably by replacing the Boolean domain {0,&nbsp;1} with the unit interval 0,1, in which case rather than only taking values 0 or 1, any value between and including 0 and 1 can be assumed.
This example is an instance of the following notion.
Entailment differs from implication in that whereas the latter is a binary ''operation'' that returns a value in a Boolean algebra, the former is a binary ''relation'' which either holds or does not hold.
The essential idea of a truth assignment is that the propositional variables are mapped to elements of a fixed Boolean algebra, and then the '''truth value''' of a propositional formula using these letters is the element of the Boolean algebra that is obtained by computing the value of the Boolean term corresponding to the formula.
Now an organization may permit multiple degrees of membership, such as novice, associate, and full.
We might notice that the columns for ''x''∧''y'' and ''x''∨''y'' in the truth tables had changed places, but that switch is immaterial.
The generic or abstract form of this tautology is "if ''P'' then ''P''", or in the language of Boolean algebra, "''P'' → ''P''".
Although every concrete Boolean algebra is a Boolean algebra, not every Boolean algebra need be concrete.
The first operation, ''x''&nbsp;→&nbsp;''y'', or C''xy'', is called '''material implication'''.
Thus "''x'' = 3 → ''x'' = 3" is a tautology by virtue of being an instance of the abstract tautology "''P'' → ''P''".
Digital logic is the application of the Boolean algebra of 0 and 1 to electronic hardware consisting of logic gates connected to form a circuit diagram.
Here ''X'' may be any set: empty, finite, infinite, or even uncountable.
Computers use two-value Boolean circuits for the above reasons.
More generally one may complement any of the eight subsets of the three ports of either an AND or OR gate.
This ability to mix external implication  and internal implication → in the one logic is among the essential differences between sequent calculus and propositional calculus.
The third operation, the complement of exclusive or, is '''equivalence''' or Boolean equality: ''x''&nbsp;≡&nbsp;''y'', or E''xy'',  is true just when ''x'' and ''y'' have the same value.
A sufficient subset of the above laws consists of the pairs of associativity, commutativity, and absorption laws, distributivity of ∧ over ∨ (or the other distributivity law—one suffices), and the two complement laws.
Complement is implemented with an inverter gate.
The double negation law can be seen by complementing the shading in the third diagram for ¬''x'', which shades the ''x'' circle.
In this sense entailment is an ''external'' form of implication, meaning external to the Boolean algebra, thinking of the reader of the sequent as also being external and interpreting and comparing antecedents and succedents in some Boolean algebra.
The operations of greatest common divisor, least common multiple, and division into ''n'' (that is, ¬''x'' = ''n''/''x''), can be shown to satisfy all the Boolean laws when their arguments range over the positive divisors of ''n''.
Although the development of mathematical logic did not follow Boole's program, the connection between his algebra and logic was later put on firm ground in the setting of algebraic logic, which also studies the algebraic systems of many other logics.
A composition of self-dual operations is a self-dual operation.
Hence no smaller example is possible, other than the degenerate algebra obtained by taking ''X'' to be empty so as to make the empty set and ''X'' coincide.
In view of the highly idiosyncratic usage of conjunctions in natural languages, Boolean algebra cannot be considered a reliable framework for interpreting them.
The power set 2''X'' of ''X'', consisting of all subsets of ''X''.
For the purposes of this definition it is irrelevant how the operations came to satisfy the laws, whether by fiat or proof.
Boolean algebras are special here, for example a relation algebra is a Boolean algebra with additional structure but it is not the case that every relation algebra is representable in the sense appropriate to relation algebras.
All occurrences of the instantiated variable must be instantiated with the same proposition, to avoid such nonsense as ''P'' → ''x'' = 3 or ''x'' = 3 → ''x'' = 4.
Disjunctive commands such ''love me or leave me'' or ''fish or cut bait'' tend to be asymmetric via the implication that one alternative is less preferable.
The 256-element free Boolean algebra on three generators is deployed in computer displays based on raster graphics, which use bit blit to manipulate whole regions consisting of pixels, relying on Boolean operations to specify how the source region should be combined with the destination, typically with the help of a third region called the mask.
All these definitions of Boolean algebra can be shown to be equivalent.
Syntactically, every Boolean term corresponds to a '''propositional formula''' of propositional logic.
But if in addition to interchanging the names of the values we also interchange the names of the two binary operations, ''now'' there is no trace of what we have done.
The elements of ''X'' need not be bit vectors or subsets but can be anything at all.
Whereas the proposition "if ''x'' = 3 then ''x''+1 = 4" depends on the meanings of such symbols as + and 1, the proposition "if ''x'' = 3 then ''x'' = 3" does not; it is true merely by virtue of its structure, and remains true whether "''x'' = 3" is replaced by "''x'' = 4" or "the moon is made of green cheese."
In an abstract setting, Boolean algebra was perfected in the late 19th century by Jevons, Schröder, Huntington, and others until it reached the modern conception of an (abstract) mathematical structure.
For example, the empirical observation that one can manipulate expressions in the algebra of sets by translating them into expressions in Boole's algebra is explained in modern terms by saying that the algebra of sets is ''a'' Boolean algebra (note the indefinite article).
Another common example is the subsets of a set ''E'': to a subset ''F'' of ''E'' is associated the indicator function that takes the value 1 on ''F'' and 0 outside ''F''.
Logic sentences that can be expressed in classical propositional calculus have an equivalent expression in Boolean algebra.
If → is in the language these last tautologies can also be written as (Φ→Ψ) ∧ (Ψ→Φ), or as two separate theorems Φ→Ψ and Ψ→Φ; if ≡ is available then the single tautology Φ ≡ Ψ can be used.
The '''Duality Principle''', also called De Morgan duality, asserts that Boolean algebra is unchanged when all dual pairs are interchanged.
For a smaller example, if ''X'' = {''a,b,c''} where ''a, b, c'' are viewed as bit positions in that order from left to right, the eight subsets {}, {''c''}, {''b''}, {''b'',''c''}, {''a''}, {''a'',''c''}, {''a'',''b''}, and {''a'',''b'',''c''} of ''X'' can be identified with the respective bit vectors 000, 001, 010, 011, 100, 101, 110, and 111.
via De Morgan's law in the form ''x''∧''y'' = ¬(¬''x''∨¬''y'')), then the equation
Solid modeling systems for computer aided design offer a variety of methods for building objects from other objects, combination by Boolean operations being one of them.
When a vector of ''n'' identical binary gates are used to combine two bit vectors each of ''n'' bits, the individual bit operations can be understood collectively as a single operation on values from a Boolean algebra with 2''n'' elements.
